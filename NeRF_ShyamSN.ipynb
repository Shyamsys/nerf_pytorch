{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "UoH2b2x1nzBx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Optional, Tuple, List, Union, Callable\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('tiny_nerf_data.npz'):\n",
        "  !wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jlO-0ghnoR7h"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('tiny_nerf_data.npz')\n",
        "images = data['images']\n",
        "poses = data['poses']\n",
        "focal = data['focal']\n",
        "\n",
        "print(f'Images shape: {images.shape}')\n",
        "print(f'Poses shape: {poses.shape}')\n",
        "print(f'Focal length: {focal}')\n",
        "\n",
        "height, width = images.shape[1:3]\n",
        "near, far = 2., 6.\n",
        "\n",
        "n_training = 100\n",
        "testimg_idx = 101\n",
        "testimg, testpose = images[testimg_idx], poses[testimg_idx]\n",
        "\n",
        "plt.imshow(testimg)\n",
        "print('Pose')\n",
        "print(testpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "YykG3OXPob7m",
        "outputId": "461400a5-243e-454f-a9e7-ee135e81ebcf"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: (106, 100, 100, 3)\n",
            "Poses shape: (106, 4, 4)\n",
            "Focal length: 138.88887889922103\n",
            "Pose\n",
            "[[ 6.8935126e-01  5.3373039e-01 -4.8982298e-01 -1.9745398e+00]\n",
            " [-7.2442728e-01  5.0788772e-01 -4.6610624e-01 -1.8789345e+00]\n",
            " [ 1.4901163e-08  6.7615211e-01  7.3676193e-01  2.9699826e+00]\n",
            " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = torch.from_numpy(data['images'][:n_training]).to(device)\n",
        "poses = torch.from_numpy(data['poses']).to(device)\n",
        "focal = torch.from_numpy(data['focal']).to(device)\n",
        "testimg = torch.from_numpy(data['images'][testimg_idx]).to(device)\n",
        "testpose = torch.from_numpy(data['poses'][testimg_idx]).to(device)"
      ],
      "metadata": {
        "id": "Jndcj04d8i2V"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rays(\n",
        "  h: int,\n",
        "  w: int,\n",
        "  f: float,\n",
        "  c: torch.Tensor\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"\n",
        "  Determine ray origin and direction for each pixel.\n",
        "  \"\"\"\n",
        "\n",
        "  # Apply pinhole camera model to find directions at each pixel\n",
        "  i, j = torch.meshgrid(\n",
        "      torch.arange(w, dtype=torch.float32).to(c),\n",
        "      torch.arange(h, dtype=torch.float32).to(c),\n",
        "      indexing='ij')\n",
        "  i, j = i.transpose(-1, -2), j.transpose(-1, -2)\n",
        "  dirs = torch.stack([(i - w * .5) / f,\n",
        "                            -(j - h * .5) / f,\n",
        "                            -torch.ones_like(i)\n",
        "                           ], dim=-1)\n",
        "\n",
        "  # Apply camera pose to directions\n",
        "  rd = torch.sum(dirs[..., None, :] * c[:3, :3], dim=-1)\n",
        "\n",
        "  # Origin is the same for all directions (the optical center)\n",
        "  ro = c[:3, -1].expand(rd.shape)\n",
        "  return ro, rd"
      ],
      "metadata": {
        "id": "VqKR8nrvpeW0"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_stratified(\n",
        "  ro: torch.Tensor,\n",
        "  rd: torch.Tensor,\n",
        "  n: float,\n",
        "  f: float,\n",
        "  n_samples: int,\n",
        "  perturb: Optional[bool] = True,\n",
        "  inverse_depth: bool = False\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"\n",
        "  Sample along ray from regularly-spaced bins.\n",
        "  \"\"\"\n",
        "\n",
        "  # Obtain samples for space integration along ray\n",
        "  ts = torch.linspace(0., 1., n_samples, device=ro.device)\n",
        "  if not inverse_depth:\n",
        "    # Sample linearly between `near` and `far`\n",
        "    zs = n * (1. - ts) + f * ts\n",
        "  else:\n",
        "    # Sample linearly in inverse depth (disparity)\n",
        "    zs = 1. / (1. / n * (1. - ts) + 1. / f * ts)\n",
        "\n",
        "  # Draw uniform samples from bins along ray\n",
        "  if perturb:\n",
        "    m = .5 * (zs[1:] + zs[:-1])\n",
        "    u = torch.cat([m, zs[-1:]], dim=-1)\n",
        "    l = torch.cat([zs[:1], m], dim=-1)\n",
        "    t_r = torch.rand([n_samples], device=zs.device)\n",
        "    zs = l + (u - l) * t_r\n",
        "  zs = zs.expand(list(ro.shape[:-1]) + [n_samples])\n",
        "\n",
        "  # Apply scale from `rays_d` and offset from `rays_o` to samples\n",
        "  # pts: (width, height, n_samples, 3)\n",
        "  pts = ro[..., None, :] + rd[..., None, :] * zs[..., :, None]\n",
        "  return pts, zs"
      ],
      "metadata": {
        "id": "WlAU_qT_pplk"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PE(nn.Module):\n",
        "  r\"\"\"\n",
        "  Sine-cosine positional encoder for input points.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "    self,\n",
        "    d_input: int,\n",
        "    n_freqs: int,\n",
        "    log_space: bool = False\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.d_input = d_input\n",
        "    self.n_freqs = n_freqs\n",
        "    self.log_space = log_space\n",
        "    self.d_output = d_input * (1 + 2 * self.n_freqs)\n",
        "    self.embed_fns = [lambda x: x]\n",
        "\n",
        "    # Define frequencies in either linear or log scale\n",
        "    if self.log_space:\n",
        "      freq_bands = 2.**torch.linspace(0., self.n_freqs - 1, self.n_freqs)\n",
        "    else:\n",
        "      freq_bands = torch.linspace(2.**0., 2.**(self.n_freqs - 1), self.n_freqs)\n",
        "\n",
        "    # Alternate sin and cos\n",
        "    for freq in freq_bands:\n",
        "      self.embed_fns.append(lambda x, freq=freq: torch.sin(x * freq))\n",
        "      self.embed_fns.append(lambda x, freq=freq: torch.cos(x * freq))\n",
        "\n",
        "  def forward(\n",
        "    self,\n",
        "    x\n",
        "  ) -> torch.Tensor:\n",
        "    r\"\"\"\n",
        "    Apply positional encoding to input.\n",
        "    \"\"\"\n",
        "    return torch.concat([fn(x) for fn in self.embed_fns], dim=-1)"
      ],
      "metadata": {
        "id": "jNHJYCv4pvYV"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeRF(nn.Module):\n",
        "  r\"\"\"\n",
        "  Neural radiance fields module.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "    self,\n",
        "    d_input: int = 3,\n",
        "    n_layers: int = 8,\n",
        "    d_filter: int = 256,\n",
        "    skip: Tuple[int] = (4,),\n",
        "    d_viewdirs: Optional[int] = None\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.d_input = d_input\n",
        "    self.skip = skip\n",
        "    self.act = nn.functional.relu\n",
        "    self.d_viewdirs = d_viewdirs\n",
        "\n",
        "    # Create model layers\n",
        "    self.layers = nn.ModuleList(\n",
        "      [nn.Linear(self.d_input, d_filter)] +\n",
        "      [nn.Linear(d_filter + self.d_input, d_filter) if i in skip \\\n",
        "       else nn.Linear(d_filter, d_filter) for i in range(n_layers - 1)]\n",
        "    )\n",
        "\n",
        "    # Bottleneck layers\n",
        "    if self.d_viewdirs is not None:\n",
        "      # If using viewdirs, split alpha and RGB\n",
        "      self.alpha_out = nn.Linear(d_filter, 1)\n",
        "      self.rgb_filters = nn.Linear(d_filter, d_filter)\n",
        "      self.branch = nn.Linear(d_filter + self.d_viewdirs, d_filter // 2)\n",
        "      self.output = nn.Linear(d_filter // 2, 3)\n",
        "    else:\n",
        "      # If no viewdirs, use simpler output\n",
        "      self.output = nn.Linear(d_filter, 4)\n",
        "\n",
        "  def forward(\n",
        "    self,\n",
        "    x: torch.Tensor,\n",
        "    viewdirs: Optional[torch.Tensor] = None\n",
        "  ) -> torch.Tensor:\n",
        "    r\"\"\"\n",
        "    Forward pass with optional view direction.\n",
        "    \"\"\"\n",
        "\n",
        "    # Cannot use viewdirs if instantiated with d_viewdirs = None\n",
        "    if self.d_viewdirs is None and viewdirs is not None:\n",
        "      raise ValueError('Cannot input x_direction if d_viewdirs was not given.')\n",
        "\n",
        "    # Apply forward pass up to bottleneck\n",
        "    x_input = x\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      x = self.act(layer(x))\n",
        "      if i in self.skip:\n",
        "        x = torch.cat([x, x_input], dim=-1)\n",
        "\n",
        "    # Apply bottleneck\n",
        "    if self.d_viewdirs is not None:\n",
        "      # Split alpha from network output\n",
        "      alpha = self.alpha_out(x)\n",
        "\n",
        "      # Pass through bottleneck to get RGB\n",
        "      x = self.rgb_filters(x)\n",
        "      x = torch.concat([x, viewdirs], dim=-1)\n",
        "      x = self.act(self.branch(x))\n",
        "      x = self.output(x)\n",
        "\n",
        "      # Concatenate alphas to output\n",
        "      x = torch.concat([x, alpha], dim=-1)\n",
        "    else:\n",
        "      # Simple output\n",
        "      x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "TXllK6L3p08x"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cpex(t: torch.Tensor) -> torch.Tensor:\n",
        "  cp = torch.cumprod(t, -1)\n",
        "  cp = torch.roll(cp, 1, -1)\n",
        "  cp[..., 0] = 1.\n",
        "  return cp\n",
        "\n",
        "def r2o(r: torch.Tensor, z: torch.Tensor, d: torch.Tensor, ns: float = 0.0, wb: bool = False) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  d = z[..., 1:] - z[..., :-1]\n",
        "  d = torch.cat([d, 1e10 * torch.ones_like(d[..., :1])], dim=-1)\n",
        "  d = d * torch.norm(d[..., None, :], dim=-1)\n",
        "  n = 0.\n",
        "  if ns > 0.:\n",
        "    n = torch.randn(r[..., 3].shape) * ns\n",
        "  a = 1.0 - torch.exp(-nn.functional.relu(r[..., 3] + n) * d)\n",
        "  w = a * cpex(1. - a + 1e-10)\n",
        "  rgb = torch.sigmoid(r[..., :3])\n",
        "  rgb_map = torch.sum(w[..., None] * rgb, dim=-2)\n",
        "  dm = torch.sum(w * z, dim=-1)\n",
        "  disp_map = 1. / torch.max(1e-10 * torch.ones_like(dm), dm / torch.sum(w, -1))\n",
        "  am = torch.sum(w, dim=-1)\n",
        "  if wb:\n",
        "    rgb_map = rgb_map + (1. - am[..., None])\n",
        "  return rgb_map, dm, am, w"
      ],
      "metadata": {
        "id": "a9nOE_Bhp5m7"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_pdf(b: torch.Tensor, w: torch.Tensor, ns: int, p: bool = False) -> torch.Tensor:\n",
        "  \"\"\"\n",
        "  Apply inverse transform sampling to a weighted set of points.\n",
        "  \"\"\"\n",
        "\n",
        "  # Normalize weights to get PDF.\n",
        "  pdf = (w + 1e-5) / torch.sum(w + 1e-5, -1, keepdims=True)\n",
        "\n",
        "  # Convert PDF to CDF.\n",
        "  cdf = torch.cumsum(pdf, dim=-1)\n",
        "  cdf = torch.cat([torch.zeros_like(cdf[..., :1]), cdf], dim=-1)\n",
        "\n",
        "  # Take sample positions to grab from CDF. Linear when perturb == 0.\n",
        "  if not p:\n",
        "    u = torch.linspace(0., 1., ns, device=cdf.device)\n",
        "    u = u.expand(list(cdf.shape[:-1]) + [ns])\n",
        "  else:\n",
        "    u = torch.rand(list(cdf.shape[:-1]) + [ns], device=cdf.device)\n",
        "\n",
        "  # Find indices along CDF where values in u would be placed.\n",
        "  u = u.contiguous()\n",
        "  i = torch.searchsorted(cdf, u, right=True)\n",
        "\n",
        "  # Clamp indices that are out of bounds.\n",
        "  b_i = torch.clamp(i - 1, min=0)\n",
        "  a_i = torch.clamp(i, max=cdf.shape[-1] - 1)\n",
        "  inds_g = torch.stack([b_i, a_i], dim=-1)\n",
        "\n",
        "  # Sample from cdf and the corresponding bin centers.\n",
        "  ms = list(inds_g.shape[:-1]) + [cdf.shape[-1]]\n",
        "  cdf_g = torch.gather(cdf.unsqueeze(-2).expand(ms), dim=-1, index=inds_g)\n",
        "  bins_g = torch.gather(b.unsqueeze(-2).expand(ms), dim=-1, index=inds_g)\n",
        "\n",
        "  # Convert samples to ray length.\n",
        "  denom = (cdf_g[..., 1] - cdf_g[..., 0])\n",
        "  denom = torch.where(denom < 1e-5, torch.ones_like(denom), denom)\n",
        "  t = (u - cdf_g[..., 0]) / denom\n",
        "  s = bins_g[..., 0] + t * (bins_g[..., 1] - bins_g[..., 0])\n",
        "\n",
        "  return s\n"
      ],
      "metadata": {
        "id": "gbGG8FMZp8NS"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_hierarchical(ro: torch.Tensor, rd: torch.Tensor, z: torch.Tensor, w: torch.Tensor, ns: int, perturb: bool = False) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  \"\"\"\n",
        "  Apply hierarchical sampling to the rays.\n",
        "  \"\"\"\n",
        "\n",
        "  # Draw samples from PDF using z_vals as bins and weights as probabilities.\n",
        "  zm = .5 * (z[..., 1:] + z[..., :-1])\n",
        "  nz = sample_pdf(zm, w[..., 1:-1], ns, perturb)\n",
        "  nz = nz.detach()\n",
        "\n",
        "  # Resample points from ray based on PDF.\n",
        "  zc, _ = torch.sort(torch.cat([z, nz], dim=-1), dim=-1)\n",
        "  p = ro[..., None, :] + rd[..., None, :] * zc[..., :, None]\n",
        "  return p, zc, nz\n"
      ],
      "metadata": {
        "id": "abAjd8wIqAZ4"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chunks(inputs: torch.Tensor, chunksize: int = 2**15) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Divide a tensor into smaller chunks for processing.\n",
        "    \"\"\"\n",
        "    return [inputs[i:i + chunksize] for i in range(0, inputs.shape[0], chunksize)]\n",
        "\n",
        "\n",
        "def prepare_chunks(points: torch.Tensor, encoding_fn: Callable[[torch.Tensor], torch.Tensor], chunksize: int = 2**15) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Encode 3D points and divide them into manageable chunks.\n",
        "    \"\"\"\n",
        "    points = points.reshape((-1, 3))\n",
        "    points = encoding_fn(points)\n",
        "    points = get_chunks(points, chunksize=chunksize)\n",
        "    return points\n",
        "\n",
        "\n",
        "def prepare_viewdirs_chunks(points: torch.Tensor, rays_d: torch.Tensor, encoding_fn: Callable[[torch.Tensor], torch.Tensor], chunksize: int = 2**15) -> List[torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Encode view directions and partition them into chunks for efficient processing.\n",
        "    \"\"\"\n",
        "    viewdirs = rays_d / torch.norm(rays_d, dim=-1, keepdim=True)\n",
        "    viewdirs = viewdirs[:, None, ...].expand(points.shape).reshape((-1, 3))\n",
        "    viewdirs = encoding_fn(viewdirs)\n",
        "    viewdirs = get_chunks(viewdirs, chunksize=chunksize)\n",
        "    return viewdirs"
      ],
      "metadata": {
        "id": "ek9LcmbJqG5a"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nerf_forward(rays_o: torch.Tensor, rays_d: torch.Tensor, near: float, far: float, encoding_fn: Callable[[torch.Tensor], torch.Tensor], coarse_model: nn.Module, kwargs_sample_stratified: dict = None, n_samples_hierarchical: int = 0, kwargs_sample_hierarchical: dict = None, fine_model = None, viewdirs_encoding_fn: Optional[Callable[[torch.Tensor], torch.Tensor]] = None, chunksize: int = 2**15) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, dict]:\n",
        "    \"\"\"\n",
        "    Perform a forward pass through a NeRF (Neural Radiance Fields) model.\n",
        "\n",
        "    Args:\n",
        "        rays_o: Origin of the rays.\n",
        "        rays_d: Direction of the rays.\n",
        "        near: Near plane distance.\n",
        "        far: Far plane distance.\n",
        "        encoding_fn: Function for encoding input points.\n",
        "        coarse_model: Coarse model for predicting radiance.\n",
        "        kwargs_sample_stratified: Additional arguments for stratified sampling.\n",
        "        n_samples_hierarchical: Number of samples for hierarchical sampling.\n",
        "        kwargs_sample_hierarchical: Additional arguments for hierarchical sampling.\n",
        "        fine_model: Fine model for refining radiance predictions.\n",
        "        viewdirs_encoding_fn: Function for encoding view directions.\n",
        "        chunksize: Size of chunks for processing.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing RGB map, depth map, accumulation map, and additional outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    if kwargs_sample_stratified is None:\n",
        "        kwargs_sample_stratified = {}\n",
        "    if kwargs_sample_hierarchical is None:\n",
        "        kwargs_sample_hierarchical = {}\n",
        "\n",
        "    query_points, z_vals = sample_stratified(rays_o, rays_d, near, far, **kwargs_sample_stratified)\n",
        "    batches = prepare_chunks(query_points, encoding_fn, chunksize=chunksize)\n",
        "    batches_viewdirs = prepare_viewdirs_chunks(query_points, rays_d, viewdirs_encoding_fn, chunksize=chunksize) if viewdirs_encoding_fn is not None else [None] * len(batches)\n",
        "\n",
        "    predictions = [coarse_model(batch, viewdirs=batch_viewdirs) for batch, batch_viewdirs in zip(batches, batches_viewdirs)]\n",
        "    raw = torch.cat(predictions, dim=0).reshape(list(query_points.shape[:2]) + [predictions[0].shape[-1]])\n",
        "    rgb_map, depth_map, acc_map, weights = r2o(raw, z_vals, rays_d)\n",
        "\n",
        "    outputs = {'z_vals_stratified': z_vals}\n",
        "\n",
        "    if n_samples_hierarchical > 0:\n",
        "        rgb_map_0, depth_map_0, acc_map_0 = rgb_map, depth_map, acc_map\n",
        "        query_points, z_vals_combined, z_hierarch = sample_hierarchical(rays_o, rays_d, z_vals, weights, n_samples_hierarchical, **kwargs_sample_hierarchical)\n",
        "        batches = prepare_chunks(query_points, encoding_fn, chunksize=chunksize)\n",
        "        batches_viewdirs = prepare_viewdirs_chunks(query_points, rays_d, viewdirs_encoding_fn, chunksize=chunksize) if viewdirs_encoding_fn is not None else [None] * len(batches)\n",
        "        fine_model = fine_model if fine_model is not None else coarse_model\n",
        "        predictions = [fine_model(batch, viewdirs=batch_viewdirs) for batch, batch_viewdirs in zip(batches, batches_viewdirs)]\n",
        "        raw = torch.cat(predictions, dim=0).reshape(list(query_points.shape[:2]) + [predictions[0].shape[-1]])\n",
        "        rgb_map, depth_map, acc_map, weights = r2o(raw, z_vals_combined, rays_d)\n",
        "        outputs.update({'z_vals_hierarchical': z_hierarch, 'rgb_map_0': rgb_map_0, 'depth_map_0': depth_map_0, 'acc_map_0': acc_map_0})\n",
        "\n",
        "    outputs.update({'rgb_map': rgb_map, 'depth_map': depth_map, 'acc_map': acc_map, 'weights': weights})\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "nBfHvd7nqJbg"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_input = 3\n",
        "n_freqs = 10\n",
        "log_space = True\n",
        "use_viewdirs = True\n",
        "n_freqs_views = 4\n",
        "\n",
        "n_samples = 64\n",
        "perturb = True\n",
        "inverse_depth = False\n",
        "\n",
        "d_filter = 128\n",
        "n_layers = 2\n",
        "skip = []\n",
        "use_fine_model = True\n",
        "d_filter_fine = 128\n",
        "n_layers_fine = 6\n",
        "\n",
        "n_samples_hierarchical = 64\n",
        "perturb_hierarchical = False\n",
        "\n",
        "lr = 5e-4\n",
        "\n",
        "n_iters = 10000\n",
        "batch_size = 2**14\n",
        "one_image_per_step = True\n",
        "chunksize = 2**14\n",
        "center_crop = True\n",
        "center_crop_iters = 50\n",
        "display_rate = 25\n",
        "\n",
        "warmup_iters = 100\n",
        "warmup_min_fitness = 10.0\n",
        "n_restarts = 10\n",
        "\n",
        "kwargs_sample_stratified = {\n",
        "    'n_samples': n_samples,\n",
        "    'perturb': perturb,\n",
        "    'inverse_depth': inverse_depth\n",
        "}\n",
        "kwargs_sample_hierarchical = {\n",
        "    'perturb': perturb\n",
        "}"
      ],
      "metadata": {
        "id": "0JCVedS3qF-h"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_samples(z_vals: torch.Tensor, z_hierarch: Optional[torch.Tensor] = None, ax: Optional[np.ndarray] = None):\n",
        "    \"\"\"\n",
        "    Plot stratified and hierarchical samples.\n",
        "    \"\"\"\n",
        "    y_vals = 1 + np.zeros_like(z_vals)\n",
        "\n",
        "    if ax is None:\n",
        "        ax = plt.subplot()\n",
        "    ax.plot(z_vals, y_vals, 'b-o')\n",
        "    if z_hierarch is not None:\n",
        "        y_hierarch = np.zeros_like(z_hierarch)\n",
        "        ax.plot(z_hierarch, y_hierarch, 'r-o')\n",
        "    ax.set_ylim([-1, 2])\n",
        "    ax.set_title('Stratified Samples (blue) and Hierarchical Samples (red)')\n",
        "    ax.axes.yaxis.set_visible(False)\n",
        "    ax.grid(True)\n",
        "    return ax\n",
        "\n",
        "\n",
        "def crop_center(img: torch.Tensor, frac: float = 0.5) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Crop the center square from an image.\n",
        "    \"\"\"\n",
        "    h_offset = round(img.shape[0] * (frac / 2))\n",
        "    w_offset = round(img.shape[1] * (frac / 2))\n",
        "    return img[h_offset:-h_offset, w_offset:-w_offset]\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"\n",
        "    Helper class for early stopping based on a fitness criterion.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience: int = 30, margin: float = 1e-4):\n",
        "        self.best_fitness = 0.0  # In our case PSNR\n",
        "        self.best_iter = 0\n",
        "        self.margin = margin\n",
        "        self.patience = patience or float('inf')  # epochs to wait after fitness stops improving to stop\n",
        "\n",
        "    def __call__(self, iter: int, fitness: float):\n",
        "        \"\"\"\n",
        "        Check if the criterion for stopping is met.\n",
        "        \"\"\"\n",
        "        if (fitness - self.best_fitness) > self.margin:\n",
        "            self.best_iter = iter\n",
        "            self.best_fitness = fitness\n",
        "        delta = iter - self.best_iter\n",
        "        stop = delta >= self.patience  # stop training if patience exceeded\n",
        "        return stop"
      ],
      "metadata": {
        "id": "2uFsagB4qMcX"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_models():\n",
        "    \"\"\"\n",
        "    Initialize models, encoders, and optimizer for NeRF training.\n",
        "    \"\"\"\n",
        "    # Encoders\n",
        "    encoder = PE(d_input, n_freqs, log_space=log_space)\n",
        "    encode = lambda x: encoder(x)\n",
        "\n",
        "    # View direction encoders\n",
        "    if use_viewdirs:\n",
        "        encoder_viewdirs = PE(d_input, n_freqs_views, log_space=log_space)\n",
        "        encode_viewdirs = lambda x: encoder_viewdirs(x)\n",
        "        d_viewdirs = encoder_viewdirs.d_output\n",
        "    else:\n",
        "        encode_viewdirs = None\n",
        "        d_viewdirs = None\n",
        "\n",
        "    # Models\n",
        "    model = NeRF(encoder.d_output, n_layers=n_layers, d_filter=d_filter, skip=skip, d_viewdirs=d_viewdirs)\n",
        "    model.to(device)\n",
        "    model_params = list(model.parameters())\n",
        "    if use_fine_model:\n",
        "        fine_model = NeRF(encoder.d_output, n_layers=n_layers, d_filter=d_filter, skip=skip, d_viewdirs=d_viewdirs)\n",
        "        fine_model.to(device)\n",
        "        model_params += list(fine_model.parameters())\n",
        "    else:\n",
        "        fine_model = None\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(model_params, lr=lr)\n",
        "\n",
        "    # Early Stopping\n",
        "    warmup_stopper = EarlyStopping(patience=50)\n",
        "\n",
        "    return model, fine_model, encode, encode_viewdirs, optimizer, warmup_stopper"
      ],
      "metadata": {
        "id": "FQ9aSTbwqPhk"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  r\"\"\"\n",
        "  Launch training session for NeRF.\n",
        "  \"\"\"\n",
        "  # Shuffle rays across all images.\n",
        "  if not one_image_per_step:\n",
        "    height, width = images.shape[1:3]\n",
        "    all_rays = torch.stack([torch.stack(get_rays(height, width, focal, p), 0)\n",
        "                        for p in poses[:n_training]], 0)\n",
        "    rays_rgb = torch.cat([all_rays, images[:, None]], 1)\n",
        "    rays_rgb = torch.permute(rays_rgb, [0, 2, 3, 1, 4])\n",
        "    rays_rgb = rays_rgb.reshape([-1, 3, 3])\n",
        "    rays_rgb = rays_rgb.type(torch.float32)\n",
        "    rays_rgb = rays_rgb[torch.randperm(rays_rgb.shape[0])]\n",
        "    i_batch = 0\n",
        "\n",
        "  train_psnrs = []\n",
        "  val_psnrs = []\n",
        "  iternums = []\n",
        "  for i in trange(n_iters):\n",
        "    model.train()\n",
        "\n",
        "    if one_image_per_step:\n",
        "      # Randomly pick an image as the target.\n",
        "      target_img_idx = np.random.randint(images.shape[0])\n",
        "      target_img = images[target_img_idx].to(device)\n",
        "      if center_crop and i < center_crop_iters:\n",
        "        target_img = crop_center(target_img)\n",
        "      height, width = target_img.shape[:2]\n",
        "      target_pose = poses[target_img_idx].to(device)\n",
        "      rays_o, rays_d = get_rays(height, width, focal, target_pose)\n",
        "      rays_o = rays_o.reshape([-1, 3])\n",
        "      rays_d = rays_d.reshape([-1, 3])\n",
        "    else:\n",
        "      # Random over all images.\n",
        "      batch = rays_rgb[i_batch:i_batch + batch_size]\n",
        "      batch = torch.transpose(batch, 0, 1)\n",
        "      rays_o, rays_d, target_img = batch\n",
        "      height, width = target_img.shape[:2]\n",
        "      i_batch += batch_size\n",
        "      # Shuffle after one epoch\n",
        "      if i_batch >= rays_rgb.shape[0]:\n",
        "          rays_rgb = rays_rgb[torch.randperm(rays_rgb.shape[0])]\n",
        "          i_batch = 0\n",
        "    target_img = target_img.reshape([-1, 3])\n",
        "\n",
        "    # Run one iteration of TinyNeRF and get the rendered RGB image.\n",
        "    outputs = nerf_forward(rays_o, rays_d,\n",
        "                           near, far, encode, model,\n",
        "                           kwargs_sample_stratified=kwargs_sample_stratified,\n",
        "                           n_samples_hierarchical=n_samples_hierarchical,\n",
        "                           kwargs_sample_hierarchical=kwargs_sample_hierarchical,\n",
        "                           fine_model=fine_model,\n",
        "                           viewdirs_encoding_fn=encode_viewdirs,\n",
        "                           chunksize=chunksize)\n",
        "\n",
        "    # Check for any numerical issues.\n",
        "    for k, v in outputs.items():\n",
        "      if torch.isnan(v).any():\n",
        "        print(f\"! [Numerical Alert] {k} contains NaN.\")\n",
        "      if torch.isinf(v).any():\n",
        "        print(f\"! [Numerical Alert] {k} contains Inf.\")\n",
        "\n",
        "    # Backprop!\n",
        "    rgb_predicted = outputs['rgb_map']\n",
        "    loss = torch.nn.functional.mse_loss(rgb_predicted, target_img)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    psnr = -10. * torch.log10(loss)\n",
        "    train_psnrs.append(psnr.item())\n",
        "\n",
        "    # Evaluate testimg at given display rate.\n",
        "    if i % display_rate == 0:\n",
        "      model.eval()\n",
        "      height, width = testimg.shape[:2]\n",
        "      rays_o, rays_d = get_rays(height, width, focal, testpose)\n",
        "      rays_o = rays_o.reshape([-1, 3])\n",
        "      rays_d = rays_d.reshape([-1, 3])\n",
        "      outputs = nerf_forward(rays_o, rays_d,\n",
        "                             near, far, encode, model,\n",
        "                             kwargs_sample_stratified=kwargs_sample_stratified,\n",
        "                             n_samples_hierarchical=n_samples_hierarchical,\n",
        "                             kwargs_sample_hierarchical=kwargs_sample_hierarchical,\n",
        "                             fine_model=fine_model,\n",
        "                             viewdirs_encoding_fn=encode_viewdirs,\n",
        "                             chunksize=chunksize)\n",
        "\n",
        "      rgb_predicted = outputs['rgb_map']\n",
        "      loss = torch.nn.functional.mse_loss(rgb_predicted, testimg.reshape(-1, 3))\n",
        "      print(\"Loss:\", loss.item())\n",
        "      val_psnr = -10. * torch.log10(loss)\n",
        "      val_psnrs.append(val_psnr.item())\n",
        "      iternums.append(i)\n",
        "\n",
        "      # Plot example outputs\n",
        "      fig, ax = plt.subplots(1, 4, figsize=(24,4), gridspec_kw={'width_ratios': [1, 1, 1, 3]})\n",
        "      ax[0].imshow(rgb_predicted.reshape([height, width, 3]).detach().cpu().numpy())\n",
        "      ax[0].set_title(f'Iteration: {i}')\n",
        "      ax[1].imshow(testimg.detach().cpu().numpy())\n",
        "      ax[1].set_title(f'Target')\n",
        "      ax[2].plot(range(0, i + 1), train_psnrs, 'r')\n",
        "      ax[2].plot(iternums, val_psnrs, 'b')\n",
        "      ax[2].set_title('PSNR (train=red, val=blue')\n",
        "      z_vals_strat = outputs['z_vals_stratified'].view((-1, n_samples))\n",
        "      z_sample_strat = z_vals_strat[z_vals_strat.shape[0] // 2].detach().cpu().numpy()\n",
        "      if 'z_vals_hierarchical' in outputs:\n",
        "        z_vals_hierarch = outputs['z_vals_hierarchical'].view((-1, n_samples_hierarchical))\n",
        "        z_sample_hierarch = z_vals_hierarch[z_vals_hierarch.shape[0] // 2].detach().cpu().numpy()\n",
        "      else:\n",
        "        z_sample_hierarch = None\n",
        "      _ = plot_samples(z_sample_strat, z_sample_hierarch, ax=ax[3])\n",
        "      ax[3].margins(0)\n",
        "      plt.show()\n",
        "\n",
        "    # Check PSNR for issues and stop if any are found.\n",
        "    if i == warmup_iters - 1:\n",
        "      if val_psnr < warmup_min_fitness:\n",
        "        print(f'Val PSNR {val_psnr} below warmup_min_fitness {warmup_min_fitness}. Stopping...')\n",
        "        return False, train_psnrs, val_psnrs\n",
        "    elif i < warmup_iters:\n",
        "      if warmup_stopper is not None and warmup_stopper(i, psnr):\n",
        "        print(f'Train PSNR flatlined at {psnr} for {warmup_stopper.patience} iters. Stopping...')\n",
        "        return False, train_psnrs, val_psnrs\n",
        "\n",
        "  return True, train_psnrs, val_psnrs"
      ],
      "metadata": {
        "id": "KeTx9q8BqSL3"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training session(s)\n",
        "for _ in range(n_restarts):\n",
        "    model, fine_model, encode, encode_viewdirs, optimizer, warmup_stopper = init_models()\n",
        "    success, train_psnrs, val_psnrs = train()\n",
        "    if success and val_psnrs[-1] >= warmup_min_fitness:\n",
        "        print('Training successful!')\n",
        "        break\n",
        "\n",
        "print('')\n",
        "print(f'Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "ayGA1qfVqVfc",
        "outputId": "aa025ddc-8898-45b7-d65c-2049a9db320f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'n_restarts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-342246db8e95>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run training session(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_restarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfine_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_viewdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_stopper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_psnrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_psnrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval_psnrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mwarmup_min_fitness\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'n_restarts' is not defined"
          ]
        }
      ]
    }
  ]
}